{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按台站的年份来记录，合成大文件\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import ipdb\n",
    "\n",
    "# 假设所有 npz 文件都位于该文件夹中\n",
    "input_directory = 'G:/云南巧家宽频带数据/denoised_mseed/QJ042022/results'\n",
    "output_hdf5 = 'G:/云南巧家宽频带数据/denoised_h5/QJ042022_denoised.hdf5'\n",
    "\n",
    "# 定义每个 npz 文件的时长（单位：秒）和合并后的时长\n",
    "segment_duration = 30  # 每个 npz 文件对应的时间（30秒）\n",
    "combined_duration = 200  # 合并后的时间（200秒）\n",
    "needed_samples = combined_duration*100  # 当前需要的总时长（初始为 200s）\n",
    "\n",
    "\n",
    "# 获取所有 npz 文件的路径列表\n",
    "npz_files = sorted([f for f in os.listdir(input_directory) if f.endswith('.npz')])\n",
    "\n",
    "# 初始化变量\n",
    "wave_counter = 0\n",
    "wave_data = []  # 用于存储合并的波形数据\n",
    "leftover_data = None  # 用于存储上一个文件剩余的 10 秒数据\n",
    "\n",
    "# 打开 hdf5 文件，准备写入\n",
    "with h5py.File(output_hdf5, 'w') as hdf5_file:\n",
    "    for i, npz_file in enumerate(npz_files):\n",
    "        # 读取 npz 文件的波形数据\n",
    "        #ipdb.set_trace()\n",
    "        file_path = os.path.join(input_directory, npz_file)\n",
    "        npz_data = np.load(file_path)\n",
    "        \n",
    "        waveform = npz_data['data']\n",
    "        \n",
    "  \n",
    "        \n",
    "        # 如果剩下所需截取的时长不足一个30s，则截取所需的，将其合并并存储到 hdf5 文件中\n",
    "        if wave_data:\n",
    "            current_samples = (np.concatenate(wave_data, axis=0)).shape[0]\n",
    "        else:\n",
    "            current_samples = 0\n",
    "        if needed_samples - current_samples <= segment_duration*100:\n",
    "            # 需要截取的时长\n",
    "            needed_waveform_part = needed_samples - current_samples\n",
    "            # 截取所需的 200 秒部分\n",
    "            wave_data.append(waveform[:needed_waveform_part])\n",
    "            \n",
    "            # 将剩余的部分（10 秒）保存，供下次使用\n",
    "            leftover_data = waveform[needed_waveform_part:]\n",
    "            print(\"Waveform shape before concatenation:\", waveform.shape)\n",
    "            # 合并当前 200 秒的波形数据\n",
    "            combined_wave = np.concatenate(wave_data, axis=0)\n",
    "            combined_wave = combined_wave.squeeze(axis=1)\n",
    "            print(\"Combined wave shape after concatenation:\", combined_wave.shape)\n",
    "          \n",
    "            #base_name = os.path.basename(npz_file)\n",
    "            parts = npz_file.split('_')\n",
    "            station_id = parts[0]\n",
    "            date_time_part = parts[3]  # 提取倒数第二部分，即日期时间部分\n",
    "            hour_part = parts[-3].split('.')[0]\n",
    "            \n",
    "            # 存储到 hdf5 文件中，以 \"wave_x\" 为组名\n",
    "            group_name = f'earthquake/{station_id}{date_time_part}.{hour_part[0:4]}{wave_counter + 1:02}'\n",
    "            hdf5_file.create_dataset(group_name, data=combined_wave)\n",
    "            print(f\"Saved {group_name} to {output_hdf5}\")\n",
    "\n",
    "            # 重置变量，准备处理下一个 200 秒的波形\n",
    "            wave_counter += 1\n",
    "            wave_data = []\n",
    "        else:\n",
    "            # 如果有剩余的 10 秒数据，先将其拼接到当前波形前面\n",
    "            if leftover_data is not None:\n",
    "                waveform = np.concatenate([leftover_data, waveform], axis=0)\n",
    "                leftover_data = None# 当前波形未达到 200 秒，直接添加到 wave_data 列表中\n",
    "            # 当前波形未达到 200 秒，直接添加到 wave_data 列表中\n",
    "            wave_data.append(waveform)\n",
    "            \n",
    "    # 如果最后剩余的波形数据不足 200 秒，也保存（可选）\n",
    "    # if wave_data:\n",
    "    #     combined_wave = np.concatenate(wave_data, axis=0)\n",
    "    #     group_name = f'wave_{wave_counter}'\n",
    "    #     hdf5_file.create_dataset(group_name, data=combined_wave)\n",
    "    #     print(f\"Saved remaining {group_name} to {output_hdf5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按具体每个月来记录，合成小文件\n",
    "# 多个segment组合成一个200s的波形，每个月所有的200s波形存在h5里\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import ipdb\n",
    "\n",
    "# 假设所有 npz 文件都位于该文件夹中\n",
    "input_directory = 'G:/云南巧家宽频带数据/denoised_mseed/QJ01202208/results'\n",
    "output_hdf5 = 'G:/云南巧家宽频带数据/denoised_h5/QJ01202208_denoised.hdf5'\n",
    "\n",
    "# 定义每个 npz 文件的时长（单位：秒）和合并后的时长\n",
    "segment_duration = 30  # 每个 npz 文件对应的时间（30秒）\n",
    "combined_duration = 200  # 合并后的时间（200秒）\n",
    "needed_samples = combined_duration*100  # 当前需要的总时长（初始为 200s）\n",
    "\n",
    "# 计算每次合并需要的文件数量\n",
    "# files_per_wave = combined_duration // segment_duration\n",
    "# remaining_duration = needed_samples % (segment_duration*100)  # 剩余未满 30 秒的部分（这里是 20秒）\n",
    "\n",
    "\n",
    "# 获取所有 npz 文件的路径列表\n",
    "npz_files = sorted([f for f in os.listdir(input_directory) if f.endswith('.npz')])\n",
    "\n",
    "# 初始化变量\n",
    "wave_counter = 0\n",
    "wave_data = []  # 用于存储合并的波形数据\n",
    "leftover_data = None  # 用于存储上一个文件剩余的数据\n",
    "\n",
    "# 打开 hdf5 文件，准备写入\n",
    "with h5py.File(output_hdf5, 'w') as hdf5_file:\n",
    "    #ipdb.set_trace()\n",
    "    for i, npz_file in enumerate(npz_files):\n",
    "        # 读取 npz 文件的波形数据\n",
    "        #ipdb.set_trace()\n",
    "        file_path = os.path.join(input_directory, npz_file)\n",
    "        npz_data = np.load(file_path)\n",
    "        \n",
    "        waveform = npz_data['data']   # (3000,1,3)\n",
    "        \n",
    "        \n",
    "        # 如果剩下所需截取的时长不足一个30s，则截取所需的，将其合并并存储到 hdf5 文件中\n",
    "        if wave_data:\n",
    "            current_samples = (np.concatenate(wave_data, axis=0)).shape[0]\n",
    "        else:\n",
    "            current_samples = 0\n",
    "        if needed_samples - current_samples <= segment_duration*100:\n",
    "            # 需要截取的时长\n",
    "            \n",
    "            needed_waveform_part = needed_samples - current_samples\n",
    "            # 截取所需的 200 秒部分\n",
    "            wave_data.append(waveform[:needed_waveform_part])\n",
    "            \n",
    "            # 将剩余的部分（10 秒）保存，供下次使用\n",
    "            leftover_data = waveform[needed_waveform_part:]\n",
    "            print(\"Waveform shape before concatenation:\", waveform.shape)\n",
    "            # 合并当前 200 秒的波形数据\n",
    "            combined_wave = np.concatenate(wave_data, axis=0)\n",
    "            combined_wave = combined_wave.squeeze(axis=1)\n",
    "            print(\"Combined wave shape after concatenation:\", combined_wave.shape)\n",
    "            # (20000,1,3)\n",
    "            #base_name = os.path.basename(npz_file)\n",
    "            # parts = npz_file.split('_')\n",
    "            # station_id = parts[0]\n",
    "            # date_time_part = parts[3]  # 提取倒数第二部分，即日期时间部分\n",
    "            # hour_part = parts[-3].split('.')[0]\n",
    "            \n",
    "            # 存储到 hdf5 文件中，以 \"wave_x\" 为组名\n",
    "            group_name = f'earthquake/{wave_counter + 1:02}'\n",
    "            hdf5_file.create_dataset(group_name, data=combined_wave)\n",
    "            print(f\"Saved {group_name} to {output_hdf5}\")\n",
    "\n",
    "            # 重置变量，准备处理下一个 200 秒的波形\n",
    "            wave_counter += 1\n",
    "            wave_data = []\n",
    "        else:\n",
    "            # 如果有剩余的 10 秒数据，先将其拼接到当前波形前面\n",
    "            if leftover_data is not None:\n",
    "                waveform = np.concatenate([leftover_data, waveform], axis=0)\n",
    "                leftover_data = None# 当前波形未达到 200 秒，直接添加到 wave_data 列表中\n",
    "            wave_data.append(waveform)\n",
    "            \n",
    "    # 如果最后剩余的波形数据不足 200 秒，也保存（可选）\n",
    "    # if wave_data:\n",
    "    #     combined_wave = np.concatenate(wave_data, axis=0)\n",
    "    #     group_name = f'wave_{wave_counter}'\n",
    "    #     hdf5_file.create_dataset(group_name, data=combined_wave)\n",
    "    #     print(f\"Saved remaining {group_name} to {output_hdf5}\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqtransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
